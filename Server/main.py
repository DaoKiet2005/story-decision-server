from fastapi import FastAPI
import random
from unidecode import unidecode
from rapidfuzz import fuzz

# ===== ML =====
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB

app = FastAPI()

# ===== DATA (D·ªØ li·ªáu kh√¥ng thay ƒë·ªïi) =====
funny_stories = [
    "Ba ch√†ng ng·ªëc ƒëi mua tr√¢u",
    "Th·∫ßy b√≥i xem voi",
    "Quan x·ª≠ ki·ªán",
    "C∆∞·ªùi ra n∆∞·ªõc m·∫Øt",
    "Anh Ba keo ki·ªát"
]

sad_stories = [
    "Chi·∫øc l√° cu·ªëi c√πng",
    "L√£o H·∫°c",
    "Ch√≠ Ph√®o",
    "V·ª£ nh·∫∑t",
    "Nh·ªØng ng√†y th∆° ·∫•u"
]

horror_stories = [
    "Ng√¥i nh√† hoang",
    "Con ma d∆∞·ªõi g·∫ßm gi∆∞·ªùng",
    "Chuy·∫øn xe l√∫c n·ª≠a ƒë√™m",
    "Ti·∫øng g√µ c·ª≠a trong ƒë√™m",
    "CƒÉn ph√≤ng s·ªë 13"
]

# ===== ML TRAIN (Kh√¥ng thay ƒë·ªïi) =====
train_sentences = [
    "ke truyen vui", "truyen hai huoc", "ke chuyen cuoi",
    "truyen buon", "truyen cam dong", "cau chuyen bi kich",
    "truyen ma", "kinh di", "chuyen rung ron"
]

train_labels = [
    "FUNNY_STORY", "FUNNY_STORY", "FUNNY_STORY",
    "SAD_STORY", "SAD_STORY", "SAD_STORY",
    "HORROR_STORY", "HORROR_STORY", "HORROR_STORY"
]

vectorizer = CountVectorizer()
X_train = vectorizer.fit_transform(train_sentences)

model = MultinomialNB()
model.fit(X_train, train_labels)

# ===== KEYWORDS (Kh√¥ng thay ƒë·ªïi) =====
KEYWORDS = {
    "FUNNY_STORY": ["hai", "vui", "cuoi"],
    "SAD_STORY": ["buon", "cam dong", "bi kich"],
    "HORROR_STORY": ["ma", "kinh di", "rung ron"]
}

# ===== API ƒêI·ªÄU CH·ªàNH =====
@app.post("/decision")
def decide_story(data: dict):
    raw_question = data.get("question", "")
    question = unidecode(raw_question.lower())

    decisions = []
    stories = {}
    
    # T·∫°o m·ªôt mapping d·ªÖ tra c·ª©u h∆°n
    ALL_STORIES = {
        "FUNNY_STORY": funny_stories,
        "SAD_STORY": sad_stories,
        "HORROR_STORY": horror_stories
    }

    # üîπ Fuzzy keyword matching
    for intent, keys in KEYWORDS.items():
        for k in keys:
            if fuzz.partial_ratio(k, question) > 70:
                decisions.append(intent)
                break

    # üîπ ML intent (fallback)
    X_test = vectorizer.transform([question])
    ml_intent = model.predict(X_test)[0]

    if ml_intent not in decisions:
        decisions.append(ml_intent)

    # üîπ Pick stories: Tr·∫£ v·ªÅ TO√ÄN B·ªò danh s√°ch truy·ªán (Kh√¥ng d√πng random.choice)
    for d in decisions:
        # Thay v√¨ random.choice(list), ta g√°n c·∫£ list v√†o stories[d]
        stories[d] = ALL_STORIES.get(d, []) # D√πng .get(d, []) ƒë·ªÉ tr√°nh l·ªói n·∫øu intent kh√¥ng h·ª£p l·ªá

    return {
        "question": raw_question,
        "decisions": decisions,
        "stories": stories
    }